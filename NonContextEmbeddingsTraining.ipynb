{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import modules & set up logging\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "import re\n",
    "import stanza\n",
    "stanza.download('en', processors='tokenize')\n",
    "nlp = stanza.Pipeline('en', processors='tokenize')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/slavkoz/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: 139kB [00:00, 3.59MB/s]                    \n",
      "2021-07-17 23:36:15,425 : INFO : Downloading these customized packages for language: en (English)...\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2021-07-17 23:36:15,442 : INFO : File exists: /Users/slavkoz/stanza_resources/en/tokenize/combined.pt.\n",
      "2021-07-17 23:36:15,470 : INFO : Finished downloading models and saved to /Users/slavkoz/stanza_resources.\n",
      "2021-07-17 23:36:15,487 : INFO : Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2021-07-17 23:36:15,498 : INFO : Use device: cpu\n",
      "2021-07-17 23:36:15,502 : INFO : Loading: tokenize\n",
      "2021-07-17 23:36:15,522 : INFO : Done loading processors!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class OffensiveSentences(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def __iter__(self):\n",
    "        def special_chars_or_punctuation_only(word):\n",
    "            word = re.sub('[^a-zA-Z:]', '', word)          # Remove punctuations\n",
    "            word = re.sub(\"(\\\\d|\\\\W)+\",\"\",word)            # remove special characters and digits\n",
    "            return len(word) == 0\n",
    "\n",
    "        for line in open(os.path.join('./full_textOnly_cleaned_dataset.csv'), encoding=\"utf-8\"):\n",
    "            line = re.sub('\\n', '', line)\n",
    "            #print(f\"ORIGINAL: '{line}'\")            \n",
    "            line = line.lower()                             # Convert to lowercase\n",
    "            line = re.sub(r'\\s+',' ', line)                  # Remove duplicated whitespaces\n",
    "            processed_line = [word.text for sentence in nlp(line).sentences for word in sentence.words if not special_chars_or_punctuation_only(word.text)]            \n",
    "            #print(f\"PROCESSED: '{processed_line}'\")\n",
    "            yield processed_line\n",
    " \n",
    "sentences = OffensiveSentences() # a memory-friendly iterator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model = Word2Vec(sentences, min_count=2, vector_size=50, workers=4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-17 23:36:15,807 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ORIGINAL: '\"Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\"'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-17 23:36:16,308 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PROCESSED: '['explanation', 'why', 'the', 'edits', 'made', 'under', 'my', 'username', 'hardcore', 'metallica', 'fan', 'were', 'reverted', 'they', 'were', \"n't\", 'vandalisms', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fac', 'and', 'please', 'do', \"n't\", 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', \"i'm\", 'retired', 'now']'\n",
      "ORIGINAL: '\"D'aww! He matches this background colour I'm seemingly stuck with. Thanks. (talk) 21:51, January 11, 2016 (UTC)\"'\n",
      "PROCESSED: '['d', 'aww', 'he', 'matches', 'this', 'background', 'colour', \"i'm\", 'seemingly', 'stuck', 'with', 'thanks', 'talk', 'january', 'utc']'\n",
      "ORIGINAL: '\"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\"'\n",
      "PROCESSED: '['hey', 'man', \"i'm\", 'really', 'not', 'trying', 'to', 'edit', 'war', 'it', \"'s\", 'just', 'that', 'this', 'guy', 'is', 'constantly', 'removing', 'relevant', 'information', 'and', 'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my', 'talk', 'page', 'he', 'seems', 'to', 'care', 'more', 'about', 'the', 'formatting', 'than', 'the', 'actual', 'info']'\n",
      "ORIGINAL: '\"More I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of types of accidents -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport\"'\n",
      "PROCESSED: '['more', 'i', 'ca', \"n't\", 'make', 'any', 'real', 'suggestions', 'on', 'improvement', 'i', 'wondered', 'if', 'the', 'section', 'statistics', 'should', 'be', 'later', 'on', 'or', 'a', 'subsection', 'of', 'types', 'of', 'accidents', 'i', 'think', 'the', 'references', 'may', 'need', 'tidying', 'so', 'that', 'they', 'are', 'all', 'in', 'the', 'exact', 'same', 'format', 'ie', 'date', 'format', 'etc', 'i', 'can', 'do', 'that', 'later', 'on', 'if', 'no', '-one', 'else', 'does', 'first', 'if', 'you', 'have', 'any', 'preferences', 'for', 'formatting', 'style', 'on', 'references', 'or', 'want', 'to', 'do', 'it', 'yourself', 'please', 'let', 'me', 'know', 'there', 'appears', 'to', 'be', 'a', 'backlog', 'on', 'articles', 'for', 'review', 'so', 'i', 'guess', 'there', 'may', 'be', 'a', 'delay', 'until', 'a', 'reviewer', 'turns', 'up', 'it', \"'s\", 'listed', 'in', 'the', 'relevant', 'form', 'eg', 'wikipedia:good_article_nominations#transport']'\n",
      "ORIGINAL: '\"You, sir, are my hero. Any chance you remember what page that's on?\"'\n",
      "PROCESSED: '['you', 'sir', 'are', 'my', 'hero', 'any', 'chance', 'you', 'remember', 'what', 'page', 'that', \"'s\", 'on']'\n",
      "ORIGINAL: '\"Congratulations from me as well, use the tools well. · talk\"'\n",
      "PROCESSED: '['congratulations', 'from', 'me', 'as', 'well', 'use', 'the', 'tools', 'well', 'talk']'\n",
      "ORIGINAL: 'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK'\n",
      "PROCESSED: '['cocksucker', 'before', 'you', 'piss', 'around', 'on', 'my', 'work']'\n",
      "ORIGINAL: '\"Your vandalism to the Matt Shirvington article has been reverted. Please don't do it again, or you will be banned.\"'\n",
      "PROCESSED: '['your', 'vandalism', 'to', 'the', 'matt', 'shirvington', 'article', 'has', 'been', 'reverted', 'please', 'do', \"n't\", 'do', 'it', 'again', 'or', 'you', 'will', 'be', 'banned']'\n",
      "ORIGINAL: '\"Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169\"'\n",
      "PROCESSED: '['sorry', 'if', 'the', 'word', 'nonsense', 'was', 'offensive', 'to', 'you', 'anyway', \"i'm\", 'not', 'intending', 'to', 'write', 'anything', 'in', 'the', 'article', 'wow', 'they', 'would', 'jump', 'on', 'me', 'for', 'vandalism', \"i'm\", 'merely', 'requesting', 'that', 'it', 'be', 'more', 'encyclopedic', 'so', 'one', 'can', 'use', 'it', 'for', 'school', 'as', 'a', 'reference', 'i', 'have', 'been', 'to', 'the', 'selective', 'breeding', 'page', 'but', 'it', \"'s\", 'almost', 'a', 'stub', 'it', 'points', 'to', 'animal', 'breeding', 'which', 'is', 'a', 'short', 'messy', 'article', 'that', 'gives', 'you', 'no', 'info', 'there', 'must', 'be', 'someone', 'around', 'with', 'expertise', 'in', 'eugenics']'\n",
      "ORIGINAL: 'alignment on this subject and which are contrary to those of DuLithgow'\n",
      "PROCESSED: '['alignment', 'on', 'this', 'subject', 'and', 'which', 'are', 'contrary', 'to', 'those', 'of', 'dulithgow']'\n",
      "ORIGINAL: '\"Fair use rationale for Image:Wonju.jpg Thanks for uploading Image:Wonju.jpg. I notice the image page specifies that the image is being used under fair use but there is no explanation or rationale as to why its use in Wikipedia articles constitutes fair use. In addition to the boilerplate fair use template, you must also write out on the image description page a specific explanation or rationale for why using this image in each article is consistent with fair use. Please go to the image description page and edit it to include a fair use rationale. If you have uploaded other fair use media, consider checking that you have specified the fair use rationale on those pages too. You can find a list of 'image' pages you have edited by clicking on the my contributions link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting Image from the dropdown box. Note that any fair use images uploaded after 4 May, 2006, and lacking such an explanation will be deleted one week after they have been uploaded, as described on criteria for speedy deletion. If you have any questions please ask them at the Media copyright questions page. Thank you. (talk • contribs • ) Unspecified source for Image:Wonju.jpg Thanks for uploading Image:Wonju.jpg. I noticed that the file's description page currently doesn't specify who created the content, so the copyright status is unclear. If you did not create this file yourself, then you will need to specify the owner of the copyright. If you obtained it from a website, then a link to the website from which it was taken, together with a restatement of that website's terms of use of its content, is usually sufficient information. However, if the copyright holder is different from the website's publisher, then their copyright should also be acknowledged. As well as adding the source, please add a proper copyright licensing tag if the file doesn't have one already. If you created/took the picture, audio, or video then the tag can be used to release it under the GFDL. If you believe the media meets the criteria at Wikipedia:Fair use, use a tag such as or one of the other tags listed at Wikipedia:Image copyright tags#Fair use. See Wikipedia:Image copyright tags for the full list of copyright tags that you can use. If you have uploaded other files, consider checking that you have specified their source and tagged them, too. You can find a list of files you have uploaded by following [ this link]. Unsourced and untagged images may be deleted one week after they have been tagged, as described on criteria for speedy deletion. If the image is copyrighted under a non-free license (per Wikipedia:Fair use) then the image will be deleted 48 hours after . If you have any questions please ask them at the Media copyright questions page. Thank you. (talk • contribs • )\"'\n",
      "PROCESSED: '['fair', 'use', 'rationale', 'for', 'image', 'wonju.jpg', 'thanks', 'for', 'uploading', 'image:wonju.jpg', 'i', 'notice', 'the', 'image', 'page', 'specifies', 'that', 'the', 'image', 'is', 'being', 'used', 'under', 'fair', 'use', 'but', 'there', 'is', 'no', 'explanation', 'or', 'rationale', 'as', 'to', 'why', 'its', 'use', 'in', 'wikipedia', 'articles', 'constitutes', 'fair', 'use', 'in', 'addition', 'to', 'the', 'boilerplate', 'fair', 'use', 'template', 'you', 'must', 'also', 'write', 'out', 'on', 'the', 'image', 'description', 'page', 'a', 'specific', 'explanation', 'or', 'rationale', 'for', 'why', 'using', 'this', 'image', 'in', 'each', 'article', 'is', 'consistent', 'with', 'fair', 'use', 'please', 'go', 'to', 'the', 'image', 'description', 'page', 'and', 'edit', 'it', 'to', 'include', 'a', 'fair', 'use', 'rationale', 'if', 'you', 'have', 'uploaded', 'other', 'fair', 'use', 'media', 'consider', 'checking', 'that', 'you', 'have', 'specified', 'the', 'fair', 'use', 'rationale', 'on', 'those', 'pages', 'too', 'you', 'can', 'find', 'a', 'list', 'of', 'image', 'pages', 'you', 'have', 'edited', 'by', 'clicking', 'on', 'the', 'my', 'contributions', 'link', 'it', 'is', 'located', 'at', 'the', 'very', 'top', 'of', 'any', 'wikipedia', 'page', 'when', 'you', 'are', 'logged', 'in', 'and', 'then', 'selecting', 'image', 'from', 'the', 'dropdown', 'box', 'note', 'that', 'any', 'fair', 'use', 'images', 'uploaded', 'after', 'may', 'and', 'lacking', 'such', 'an', 'explanation', 'will', 'be', 'deleted', 'one', 'week', 'after', 'they', 'have', 'been', 'uploaded', 'as', 'described', 'on', 'criteria', 'for', 'speedy', 'deletion', 'if', 'you', 'have', 'any', 'questions', 'please', 'ask', 'them', 'at', 'the', 'media', 'copyright', 'questions', 'page', 'thank', 'you', 'talk', 'contribs', 'unspecified', 'source', 'for', 'image', 'wonju.jpg', 'thanks', 'for', 'uploading', 'image:wonju.jpg', 'i', 'noticed', 'that', 'the', 'file', \"'s\", 'description', 'page', 'currently', 'does', \"n't\", 'specify', 'who', 'created', 'the', 'content', 'so', 'the', 'copyright', 'status', 'is', 'unclear', 'if', 'you', 'did', 'not', 'create', 'this', 'file', 'yourself', 'then', 'you', 'will', 'need', 'to', 'specify', 'the', 'owner', 'of', 'the', 'copyright', 'if', 'you', 'obtained', 'it', 'from', 'a', 'website', 'then', 'a', 'link', 'to', 'the', 'website', 'from', 'which', 'it', 'was', 'taken', 'together', 'with', 'a', 'restatement', 'of', 'that', 'website', \"'s\", 'terms', 'of', 'use', 'of', 'its', 'content', 'is', 'usually', 'sufficient', 'information', 'however', 'if', 'the', 'copyright', 'holder', 'is', 'different', 'from', 'the', 'website', \"'s\", 'publisher', 'then', 'their', 'copyright', 'should', 'also', 'be', 'acknowledged', 'as', 'well', 'as', 'adding', 'the', 'source', 'please', 'add', 'a', 'proper', 'copyright', 'licensing', 'tag', 'if', 'the', 'file', 'does', \"n't\", 'have', 'one', 'already', 'if', 'you', 'created', 'took', 'the', 'picture', 'audio', 'or', 'video', 'then', 'the', 'tag', 'can', 'be', 'used', 'to', 'release', 'it', 'under', 'the', 'gfdl', 'if', 'you', 'believe', 'the', 'media', 'meets', 'the', 'criteria', 'at', 'wikipedia', 'fair', 'use', 'use', 'a', 'tag', 'such', 'as', 'or', 'one', 'of', 'the', 'other', 'tags', 'listed', 'at', 'wikipedia', 'image', 'copyright', 'tags', 'fair', 'use', 'see', 'wikipedia', 'image', 'copyright', 'tags', 'for', 'the', 'full', 'list', 'of', 'copyright', 'tags', 'that', 'you', 'can', 'use', 'if', 'you', 'have', 'uploaded', 'other', 'files', 'consider', 'checking', 'that', 'you', 'have', 'specified', 'their', 'source', 'and', 'tagged', 'them', 'too', 'you', 'can', 'find', 'a', 'list', 'of', 'files', 'you', 'have', 'uploaded', 'by', 'following', 'this', 'link', 'unsourced', 'and', 'untagged', 'images', 'may', 'be', 'deleted', 'one', 'week', 'after', 'they', 'have', 'been', 'tagged', 'as', 'described', 'on', 'criteria', 'for', 'speedy', 'deletion', 'if', 'the', 'image', 'is', 'copyrighted', 'under', 'a', 'non-free', 'license', 'per', 'wikipedia', 'fair', 'use', 'then', 'the', 'image', 'will', 'be', 'deleted', 'hours', 'after', 'if', 'you', 'have', 'any', 'questions', 'please', 'ask', 'them', 'at', 'the', 'media', 'copyright', 'questions', 'page', 'thank', 'you', 'talk', 'contribs']'\n",
      "ORIGINAL: 'bbq be a man and lets discuss it-maybe over the phone?'\n",
      "PROCESSED: '['bbq', 'be', 'a', 'man', 'and', 'lets', 'discuss', 'it', 'maybe', 'over', 'the', 'phone']'\n",
      "ORIGINAL: '\"Hey... what is it.. @ | talk . What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP? Ask Sityush to clean up his behavior than issue me nonsensical warnings...\"'\n",
      "PROCESSED: '['hey', 'what', 'is', 'it', 'talk', 'what', 'is', 'it', 'an', 'exclusive', 'group', 'of', 'some', 'wp', 'talibans', 'who', 'are', 'good', 'at', 'destroying', 'self', 'appointed', 'purist', 'who', 'gang', 'up', 'any', 'one', 'who', 'asks', 'them', 'questions', 'abt', 'their', 'anti-social', 'and', 'destructive', 'non', 'contribution', 'at', 'wp', 'ask', 'sityush', 'to', 'clean', 'up', 'his', 'behavior', 'than', 'issue', 'me', 'nonsensical', 'warnings']'\n",
      "ORIGINAL: '\"Before you start throwing accusations and warnings at me, lets review the edit itself-making ad hominem attacks isn't going to strengthen your argument, it will merely make it look like you are abusing your power as an admin. Now, the edit itself is relevant-this is probably the single most talked about event int he news as of late. His absence is notable, since he is the only living ex-president who did not attend. That's certainly more notable than his dedicating an aircracft carrier. I intend to revert this edit, in hopes of attracting the attention of an admin that is willing to look at the issue itself, and not throw accusations around quite so liberally. Perhaps, if you achieve a level of civility where you can do this, we can have a rational discussion on the topic and resolve the matter peacefully.\"'\n",
      "PROCESSED: '['before', 'you', 'start', 'throwing', 'accusations', 'and', 'warnings', 'at', 'me', 'lets', 'review', 'the', 'edit', 'itself', 'making', 'ad', 'hominem', 'attacks', 'is', \"n't\", 'going', 'to', 'strengthen', 'your', 'argument', 'it', 'will', 'merely', 'make', 'it', 'look', 'like', 'you', 'are', 'abusing', 'your', 'power', 'as', 'an', 'admin', 'now', 'the', 'edit', 'itself', 'is', 'relevant', 'this', 'is', 'probably', 'the', 'single', 'most', 'talked', 'about', 'event', 'int', 'he', 'news', 'as', 'of', 'late', 'his', 'absence', 'is', 'notable', 'since', 'he', 'is', 'the', 'only', 'living', 'ex-president', 'who', 'did', 'not', 'attend', 'that', \"'s\", 'certainly', 'more', 'notable', 'than', 'his', 'dedicating', 'an', 'aircracft', 'carrier', 'i', 'intend', 'to', 'revert', 'this', 'edit', 'in', 'hopes', 'of', 'attracting', 'the', 'attention', 'of', 'an', 'admin', 'that', 'is', 'willing', 'to', 'look', 'at', 'the', 'issue', 'itself', 'and', 'not', 'throw', 'accusations', 'around', 'quite', 'so', 'liberally', 'perhaps', 'if', 'you', 'achieve', 'a', 'level', 'of', 'civility', 'where', 'you', 'can', 'do', 'this', 'we', 'can', 'have', 'a', 'rational', 'discussion', 'on', 'the', 'topic', 'and', 'resolve', 'the', 'matter', 'peacefully']'\n",
      "ORIGINAL: '\"Oh, and the girl above started her arguments with me. She stuck her nose where it doesn't belong. I believe the argument was between me and Yvesnimmo. But like I said, the situation was settled and I apologized. Thanks,\"'\n",
      "PROCESSED: '['oh', 'and', 'the', 'girl', 'above', 'started', 'her', 'arguments', 'with', 'me', 'she', 'stuck', 'her', 'nose', 'where', 'it', 'does', \"n't\", 'belong', 'i', 'believe', 'the', 'argument', 'was', 'between', 'me', 'and', 'yvesnimmo', 'but', 'like', 'i', 'said', 'the', 'situation', 'was', 'settled', 'and', 'i', 'apologized', 'thanks']'\n",
      "ORIGINAL: '\"Juelz Santanas Age In 2002, Juelz Santana was 18 years old, then came February 18th, which makes Juelz turn 19 making songs with The Diplomats. The third neff to be signed to Cam's label under Roc A Fella. In 2003, he was 20 years old coming out with his own singles Santana's Town and Down. So yes, he is born in 1983. He really is, how could he be older then Lloyd Banks? And how could he be 22 when his birthday passed? The homie neff is 23 years old. 1983 - 2006 (Juelz death, god forbid if your thinking about that) equals 23. Go to your caculator and stop changing his year of birth. My god.\"'\n",
      "PROCESSED: '['juelz', 'santanas', 'age', 'in', 'juelz', 'santana', 'was', 'years', 'old', 'then', 'came', 'february', '18th', 'which', 'makes', 'juelz', 'turn', 'making', 'songs', 'with', 'the', 'diplomats', 'the', 'third', 'neff', 'to', 'be', 'signed', 'to', 'cam', \"'s\", 'label', 'under', 'roc', 'a', 'fella', 'in', 'he', 'was', 'years', 'old', 'coming', 'out', 'with', 'his', 'own', 'singles', 'santana', \"'s\", 'town', 'and', 'down', 'so', 'yes', 'he', 'is', 'born', 'in', 'he', 'really', 'is', 'how', 'could', 'he', 'be', 'older', 'then', 'lloyd', 'banks', 'and', 'how', 'could', 'he', 'be', 'when', 'his', 'birthday', 'passed', 'the', 'homie', 'neff', 'is', 'years', 'old', 'juelz', 'death', 'god', 'forbid', 'if', 'your', 'thinking', 'about', 'that', 'equals', 'go', 'to', 'your', 'caculator', 'and', 'stop', 'changing', 'his', 'year', 'of', 'birth', 'my', 'god']'\n",
      "ORIGINAL: '\"Bye! Don't look, come or think of comming back! Tosser.\"'\n",
      "PROCESSED: '['bye', 'do', \"n't\", 'look', 'come', 'or', 'think', 'of', 'comming', 'back', 'tosser']'\n",
      "ORIGINAL: 'REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski'\n",
      "PROCESSED: '['redirect', 'talk', 'voydan', 'pop', 'georgiev-', 'chernodrinski']'\n",
      "ORIGINAL: 'The Mitsurugi point made no sense - why not argue to include Hindi on Ryo Sakazaki's page to include more information?'\n",
      "PROCESSED: '['the', 'mitsurugi', 'point', 'made', 'no', 'sense', 'why', 'not', 'argue', 'to', 'include', 'hindi', 'on', 'ryo', 'sakazaki', \"'s\", 'page', 'to', 'include', 'more', 'information']'\n",
      "ORIGINAL: '\"Don't mean to bother you I see that you're writing something regarding removing anything posted here and if you do oh well but if not and you can acctually discuss this with me then even better. I'd like to ask you to take a closer look at the Premature wrestling deaths catagory and the men listed in it, surely these men belong together in some catagory. Is there anything that you think we can do with the catagory besides delting it?\"'\n",
      "PROCESSED: '['do', \"n't\", 'mean', 'to', 'bother', 'you', 'i', 'see', 'that', 'you', \"'re\", 'writing', 'something', 'regarding', 'removing', 'anything', 'posted', 'here', 'and', 'if', 'you', 'do', 'oh', 'well', 'but', 'if', 'not', 'and', 'you', 'can', 'acctually', 'discuss', 'this', 'with', 'me', 'then', 'even', 'better', \"i'd\", 'like', 'to', 'ask', 'you', 'to', 'take', 'a', 'closer', 'look', 'at', 'the', 'premature', 'wrestling', 'deaths', 'catagory', 'and', 'the', 'men', 'listed', 'in', 'it', 'surely', 'these', 'men', 'belong', 'together', 'in', 'some', 'catagory', 'is', 'there', 'anything', 'that', 'you', 'think', 'we', 'can', 'do', 'with', 'the', 'catagory', 'besides', 'delting', 'it']'\n",
      "ORIGINAL: '\"Regarding your recent edits Once again, please read WP:FILMPLOT before editing any more film articles. Your edits are simply not good, with entirely too many unnecessary details and very bad writing. Please stop before you do further damage. -The '45\"'\n",
      "PROCESSED: '['regarding', 'your', 'recent', 'edits', 'once', 'again', 'please', 'read', 'wp', 'filmplot', 'before', 'editing', 'any', 'more', 'film', 'articles', 'your', 'edits', 'are', 'simply', 'not', 'good', 'with', 'entirely', 'too', 'many', 'unnecessary', 'details', 'and', 'very', 'bad', 'writing', 'please', 'stop', 'before', 'you', 'do', 'further', 'damage', 'the']'\n",
      "ORIGINAL: '\"Good to know. About me, yeah, I'm studying now.(Deepu)\"'\n",
      "PROCESSED: '['good', 'to', 'know', 'about', 'me', 'yeah', \"i'm\", 'studying', 'now', 'deepu']'\n",
      "ORIGINAL: '\"Snowflakes are NOT always symmetrical! Under Geometry it is stated that A snowflake always has six symmetric arms. This assertion is simply not true! According to Kenneth Libbrecht, The rather unattractive irregular crystals are by far the most common variety. Someone really need to take a look at his site and get FACTS off of it because I still see a decent number of falsities on this page. (forgive me Im new at this and dont want to edit anything)\"'\n",
      "PROCESSED: '['snowflakes', 'are', 'not', 'always', 'symmetrical', 'under', 'geometry', 'it', 'is', 'stated', 'that', 'a', 'snowflake', 'always', 'has', 'six', 'symmetric', 'arms', 'this', 'assertion', 'is', 'simply', 'not', 'true', 'according', 'to', 'kenneth', 'libbrecht', 'the', 'rather', 'unattractive', 'irregular', 'crystals', 'are', 'by', 'far', 'the', 'most', 'common', 'variety', 'someone', 'really', 'need', 'to', 'take', 'a', 'look', 'at', 'his', 'site', 'and', 'get', 'facts', 'off', 'of', 'it', 'because', 'i', 'still', 'see', 'a', 'decent', 'number', 'of', 'falsities', 'on', 'this', 'page', 'forgive', 'me', 'im', 'new', 'at', 'this', 'and', 'dont', 'want', 'to', 'edit', 'anything']'\n",
      "ORIGINAL: 'The Signpost: 24 September 2012 Read this Signpost in full Single-page Unsubscribe'\n",
      "PROCESSED: '['the', 'signpost', 'september', 'read', 'this', 'signpost', 'in', 'full', 'single', 'page', 'unsubscribe']'\n",
      "ORIGINAL: '\"Re-considering 1st paragraph edit? I don't understand the reasons for 's recent edit of this article not that I'm sure that the data are necessarily wrong. Rather, I'm persuaded that the strategy of introducing academic honors in the first paragraph is an unhelpful approach to this specific subject. I note that articles about other sitting Justices have been similarly enhanced; and I also believe those changes are no improvement. In support of my view that this edit should be reverted, I would invite anyone to re-visit articles written about the following pairs of jurists. A1. Benjamin Cardozo A2. Learned Hand B1. John Marshall Harlan B2. John Marshall Harlan II The question becomes: Would the current version of the Wikipedia article about any one of them or either pair be improved by academic credentials in the introductory paragraph? I think not. Perhaps it helps to repeat a wry argument Kathleen Sullivan of Stanford Law makes when she suggests that some on the Harvard Law faculty wonder how Antonin Scalia avoided learning what others have managed to grasp about the processes of judging? I would hope this anecdote gently illustrates the point. Less humorous, but an even stronger argument is the one Clarence Thomas makes when he mentions wanting to return his law degree to Yale. At a minimum, I'm questioning this edit? It deserves to be reconsidered.\"'\n",
      "PROCESSED: '['re-', 'considering', '1st', 'paragraph', 'edit', 'i', 'do', \"n't\", 'understand', 'the', 'reasons', 'for', \"'s\", 'recent', 'edit', 'of', 'this', 'article', 'not', 'that', \"i'm\", 'sure', 'that', 'the', 'data', 'are', 'necessarily', 'wrong', 'rather', \"i'm\", 'persuaded', 'that', 'the', 'strategy', 'of', 'introducing', 'academic', 'honors', 'in', 'the', 'first', 'paragraph', 'is', 'an', 'unhelpful', 'approach', 'to', 'this', 'specific', 'subject', 'i', 'note', 'that', 'articles', 'about', 'other', 'sitting', 'justices', 'have', 'been', 'similarly', 'enhanced', 'and', 'i', 'also', 'believe', 'those', 'changes', 'are', 'no', 'improvement', 'in', 'support', 'of', 'my', 'view', 'that', 'this', 'edit', 'should', 'be', 'reverted', 'i', 'would', 'invite', 'anyone', 'to', 're-visit', 'articles', 'written', 'about', 'the', 'following', 'pairs', 'of', 'jurists', 'a1.', 'benjamin', 'cardozo', 'a', 'learned', 'hand', 'b1', 'john', 'marshall', 'harlan', 'b', 'john', 'marshall', 'harlan', 'ii', 'the', 'question', 'becomes', 'would', 'the', 'current', 'version', 'of', 'the', 'wikipedia', 'article', 'about', 'any', 'one', 'of', 'them', 'or', 'either', 'pair', 'be', 'improved', 'by', 'academic', 'credentials', 'in', 'the', 'introductory', 'paragraph', 'i', 'think', 'not', 'perhaps', 'it', 'helps', 'to', 'repeat', 'a', 'wry', 'argument', 'kathleen', 'sullivan', 'of', 'stanford', 'law', 'makes', 'when', 'she', 'suggests', 'that', 'some', 'on', 'the', 'harvard', 'law', 'faculty', 'wonder', 'how', 'antonin', 'scalia', 'avoided', 'learning', 'what', 'others', 'have', 'managed', 'to', 'grasp', 'about', 'the', 'processes', 'of', 'judging', 'i', 'would', 'hope', 'this', 'anecdote', 'gently', 'illustrates', 'the', 'point', 'less', 'humorous', 'but', 'an', 'even', 'stronger', 'argument', 'is', 'the', 'one', 'clarence', 'thomas', 'makes', 'when', 'he', 'mentions', 'wanting', 'to', 'return', 'his', 'law', 'degree', 'to', 'yale', 'at', 'a', 'minimum', \"i'm\", 'questioning', 'this', 'edit', 'it', 'deserves', 'to', 'be', 'reconsidered']'\n",
      "ORIGINAL: '\"Radial symmetry Several now extinct lineages included in the Echinodermata were bilateral such as Homostelea, or even asymmetrical such as Cothurnocystis (Stylophora). -\"'\n",
      "PROCESSED: '['radial', 'symmetry', 'several', 'now', 'extinct', 'lineages', 'included', 'in', 'the', 'echinodermata', 'were', 'bilateral', 'such', 'as', 'homostelea', 'or', 'even', 'asymmetrical', 'such', 'as', 'cothurnocystis', 'stylophora']'\n",
      "ORIGINAL: '\"There's no need to apologize. A Wikipedia article is made for reconciling knowledge about a subject from different sources, and you've done history studies and not archaeology studies, I guess. I could scan the page, e-mail it to you, and then you could ask someone to translate the page.\"'\n",
      "PROCESSED: '['there', \"'s\", 'no', 'need', 'to', 'apologize', 'a', 'wikipedia', 'article', 'is', 'made', 'for', 'reconciling', 'knowledge', 'about', 'a', 'subject', 'from', 'different', 'sources', 'and', 'you', \"'ve\", 'done', 'history', 'studies', 'and', 'not', 'archaeology', 'studies', 'i', 'guess', 'i', 'could', 'scan', 'the', 'page', 'e-mail', 'it', 'to', 'you', 'and', 'then', 'you', 'could', 'ask', 'someone', 'to', 'translate', 'the', 'page']'\n",
      "ORIGINAL: '\"Yes, because the mother of the child in the case against Michael Jackson was studied in here motives and reasonings and judged upon her character just as harshly as Wacko Jacko himself. Don't tell me to ignore it and incriminate myself. I am going to continue refuting the bullshit that Jayjg keeps throwing at me. 18:01, 16 Jun 2005 (UTC)\"'\n",
      "PROCESSED: '['yes', 'because', 'the', 'mother', 'of', 'the', 'child', 'in', 'the', 'case', 'against', 'michael', 'jackson', 'was', 'studied', 'in', 'here', 'motives', 'and', 'reasonings', 'and', 'judged', 'upon', 'her', 'character', 'just', 'as', 'harshly', 'as', 'wacko', 'jacko', 'himself', 'do', \"n't\", 'tell', 'me', 'to', 'ignore', 'it', 'and', 'incriminate', 'myself', 'i', 'am', 'going', 'to', 'continue', 'refuting', 'the', 'bullshit', 'that', 'jayjg', 'keeps', 'throwing', 'at', 'me', 'jun', 'utc']'\n",
      "ORIGINAL: 'Ok. But it will take a bit of work but I can't quite picture it. Do you have an example I can base it on? the Duck'\n",
      "PROCESSED: '['ok', 'but', 'it', 'will', 'take', 'a', 'bit', 'of', 'work', 'but', 'i', 'ca', \"n't\", 'quite', 'picture', 'it', 'do', 'you', 'have', 'an', 'example', 'i', 'can', 'base', 'it', 'on', 'the', 'duck']'\n",
      "ORIGINAL: '== A barnstar for you! == The Real Life Barnstar lets us be the stars'\n",
      "PROCESSED: '['a', 'barnstar', 'for', 'you', 'the', 'real', 'life', 'barnstar', 'lets', 'us', 'be', 'the', 'stars']'\n",
      "ORIGINAL: '\"How could I post before the block expires? The funny thing is, you think I'm being uncivil!\"'\n",
      "PROCESSED: '['how', 'could', 'i', 'post', 'before', 'the', 'block', 'expires', 'the', 'funny', 'thing', 'is', 'you', 'think', \"i'm\", 'being', 'uncivil']'\n",
      "ORIGINAL: 'Not sure about a heading of 'Fight for Freedom' what will it contain?'\n",
      "PROCESSED: '['not', 'sure', 'about', 'a', 'heading', 'of', 'fight', 'for', 'freedom', 'what', 'will', 'it', 'contain']'\n",
      "ORIGINAL: 'Praise looked at this article about 6 months ago -much improved. ]'\n",
      "PROCESSED: '['praise', 'looked', 'at', 'this', 'article', 'about', 'months', 'ago', 'much', 'improved']'\n",
      "ORIGINAL: '\"I was able to post the above list so quickly because I already had it in a text file in my hard drive I've been meaning to get around to updating the sound list for some time now. As far as generating interest I've spent four years trying to drum up more interest in freely licensed full length classical music. Unfortunately, my attempts failed - I'm still effectively the only one who does it. The classical music wikiproject was not interested, (Wikipedia_talk:WikiProject_Classical_music/Archive_5#Need_help.21Wikipedia_talk:WikiProject_Music/Archive_3#I_could_use_some_helpWikipedia_talk:WikiProject_Music/Archive_2#Raulbot.2C_and_the_music_list) So I really had given up trying to interest others. The sound list was featured on digg a while back - . It got 1600 diggs, which is IMO very impressive.\"'\n",
      "PROCESSED: '['i', 'was', 'able', 'to', 'post', 'the', 'above', 'list', 'so', 'quickly', 'because', 'i', 'already', 'had', 'it', 'in', 'a', 'text', 'file', 'in', 'my', 'hard', 'drive', \"i've\", 'been', 'meaning', 'to', 'get', 'around', 'to', 'updating', 'the', 'sound', 'list', 'for', 'some', 'time', 'now', 'as', 'far', 'as', 'generating', 'interest', \"i've\", 'spent', 'four', 'years', 'trying', 'to', 'drum', 'up', 'more', 'interest', 'in', 'freely', 'licensed', 'full', 'length', 'classical', 'music', 'unfortunately', 'my', 'attempts', 'failed', \"i'm\", 'still', 'effectively', 'the', 'only', 'one', 'who', 'does', 'it', 'the', 'classical', 'music', 'wikiproject', 'was', 'not', 'interested', 'wikipedia_talk:wikiproject_classical_music/archive_5#need_help.21wikipedia_talk:wikiproject_music/archive_3#i_could_use_some_helpwikipedia_talk:wikiproject_music/archive_2#raulbot.2c_and_the_music_list', 'so', 'i', 'really', 'had', 'given', 'up', 'trying', 'to', 'interest', 'others', 'the', 'sound', 'list', 'was', 'featured', 'on', 'digg', 'a', 'while', 'back', 'it', 'got', 'diggs', 'which', 'is', 'imo', 'very', 'impressive']'\n",
      "ORIGINAL: '\"Well, not before the process but before how we do things with subpages His RfA is listed on NoSeptember's page and you can find it if you look. September 2004 I think. I have my differences with El_C to be sure, but was surprised to see a block, so I left a note. ++: t/c\"'\n",
      "PROCESSED: '['well', 'not', 'before', 'the', 'process', 'but', 'before', 'how', 'we', 'do', 'things', 'with', 'subpages', 'his', 'rfa', 'is', 'listed', 'on', 'noseptember', \"'s\", 'page', 'and', 'you', 'can', 'find', 'it', 'if', 'you', 'look', 'september', 'i', 'think', 'i', 'have', 'my', 'differences', 'with', 'el_c', 'to', 'be', 'sure', 'but', 'was', 'surprised', 'to', 'see', 'a', 'block', 'so', 'i', 'left', 'a', 'note', 't/', 'c']'\n",
      "ORIGINAL: '\"Not at all, you are making a straw man argument here. I never claimed O'Donohue had that position, rather that practitioners and researchers in the field ignored the DSM position, which is exactly what the quote says and also something O'Donohue agrees with. Again, I was combating the notion that it was a absurd part to claim that pedophilia is a sexual orientation. Since many researchers hold this position, it would be unfair to call it absurd. The disorder part is divided in the field, some argue that it is not a disorder at all, some do. At the end of the day, it is a value judgment (as Cantor pointed out earlier in the thread), not a scientific judgement. If we choose to make this value judgment in the article, it should be stated clearly and not pretend to have a scientific basis.\"'\n",
      "PROCESSED: '['not', 'at', 'all', 'you', 'are', 'making', 'a', 'straw', 'man', 'argument', 'here', 'i', 'never', 'claimed', \"o'donohue\", 'had', 'that', 'position', 'rather', 'that', 'practitioners', 'and', 'researchers', 'in', 'the', 'field', 'ignored', 'the', 'dsm', 'position', 'which', 'is', 'exactly', 'what', 'the', 'quote', 'says', 'and', 'also', 'something', \"o'donohue\", 'agrees', 'with', 'again', 'i', 'was', 'combating', 'the', 'notion', 'that', 'it', 'was', 'a', 'absurd', 'part', 'to', 'claim', 'that', 'pedophilia', 'is', 'a', 'sexual', 'orientation', 'since', 'many', 'researchers', 'hold', 'this', 'position', 'it', 'would', 'be', 'unfair', 'to', 'call', 'it', 'absurd', 'the', 'disorder', 'part', 'is', 'divided', 'in', 'the', 'field', 'some', 'argue', 'that', 'it', 'is', 'not', 'a', 'disorder', 'at', 'all', 'some', 'do', 'at', 'the', 'end', 'of', 'the', 'day', 'it', 'is', 'a', 'value', 'judgment', 'as', 'cantor', 'pointed', 'out', 'earlier', 'in', 'the', 'thread', 'not', 'a', 'scientific', 'judgement', 'if', 'we', 'choose', 'to', 'make', 'this', 'value', 'judgment', 'in', 'the', 'article', 'it', 'should', 'be', 'stated', 'clearly', 'and', 'not', 'pretend', 'to', 'have', 'a', 'scientific', 'basis']'\n",
      "ORIGINAL: '\"Mainland Asia includes the lower basin of China's Yangtze River as well as Korea. But being specific is fine too. I just found a citation for a more comprehensive DNA study by Hammer below, rather than our generarizations and speculation so far. Citation for Yayoi culture was brought to Japan by migrants from Korea, who in turn trace their roots to southeast Asia/south China. 2005 DNA study by Hammer Describes the Yayoi migration from Korea based on the O-SRY(465) genes and other genes with close lineage (haplogroups O-M122 and O-M95). Reiterates that the entire O haplogroup has been proposed to have a Southeast Asian origin. (Their definition of Southeast Asia includes southern China). Then hypothesizes that the dispersals of Neolithic farmers from Southeast Asia also brought haplogroup O lineages to Korea and eventually to Japan. In the concluding paragraph, it states we propose that the Yayoi Y chromosomes descend from prehistoric farmers that had their origins in southeastern Asia, perhaps going back to the origin of agriculture in this region. Hammer's DNA study is based on a global sample consisted of > 2,500 males from 39 Asian populations, including six populations sampled from across the Japanese archipelago.\"'\n",
      "PROCESSED: '['mainland', 'asia', 'includes', 'the', 'lower', 'basin', 'of', 'china', \"'s\", 'yangtze', 'river', 'as', 'well', 'as', 'korea', 'but', 'being', 'specific', 'is', 'fine', 'too', 'i', 'just', 'found', 'a', 'citation', 'for', 'a', 'more', 'comprehensive', 'dna', 'study', 'by', 'hammer', 'below', 'rather', 'than', 'our', 'generarizations', 'and', 'speculation', 'so', 'far', 'citation', 'for', 'yayoi', 'culture', 'was', 'brought', 'to', 'japan', 'by', 'migrants', 'from', 'korea', 'who', 'in', 'turn', 'trace', 'their', 'roots', 'to', 'southeast', 'asia', 'south', 'china', 'dna', 'study', 'by', 'hammer', 'describes', 'the', 'yayoi', 'migration', 'from', 'korea', 'based', 'on', 'the', 'o-sry', 'genes', 'and', 'other', 'genes', 'with', 'close', 'lineage', 'haplogroups', 'o', '-m', 'and', 'o', '-m95', 'reiterates', 'that', 'the', 'entire', 'o', 'haplogroup', 'has', 'been', 'proposed', 'to', 'have', 'a', 'southeast', 'asian', 'origin', 'their', 'definition', 'of', 'southeast', 'asia', 'includes', 'southern', 'china', 'then', 'hypothesizes', 'that', 'the', 'dispersals', 'of', 'neolithic', 'farmers', 'from', 'southeast', 'asia', 'also', 'brought', 'haplogroup', 'o', 'lineages', 'to', 'korea', 'and', 'eventually', 'to', 'japan', 'in', 'the', 'concluding', 'paragraph', 'it', 'states', 'we', 'propose', 'that', 'the', 'yayoi', 'y', 'chromosomes', 'descend', 'from', 'prehistoric', 'farmers', 'that', 'had', 'their', 'origins', 'in', 'southeastern', 'asia', 'perhaps', 'going', 'back', 'to', 'the', 'origin', 'of', 'agriculture', 'in', 'this', 'region', 'hammer', \"'s\", 'dna', 'study', 'is', 'based', 'on', 'a', 'global', 'sample', 'consisted', 'of', 'males', 'from', 'asian', 'populations', 'including', 'six', 'populations', 'sampled', 'from', 'across', 'the', 'japanese', 'archipelago']'\n",
      "ORIGINAL: '\"pretty much everyone from warren county/surrounding regions was born at glens falls hospital. myself included. however, i'm not sure this qualifies anyone as being a glens falls native. rachel ray is, i believe, actually from the town of lake luzerne. —The preceding unsigned comment was added by 70.100.229.154 04:28:57, August 19, 2007 (UTC)\"'\n",
      "PROCESSED: '['pretty', 'much', 'everyone', 'from', 'warren', 'county', 'surrounding', 'regions', 'was', 'born', 'at', 'glens', 'falls', 'hospital', 'myself', 'included', 'however', \"i'm\", 'not', 'sure', 'this', 'qualifies', 'anyone', 'as', 'being', 'a', 'glens', 'falls', 'native', 'rachel', 'ray', 'is', 'i', 'believe', 'actually', 'from', 'the', 'town', 'of', 'lake', 'luzerne', 'the', 'preceding', 'unsigned', 'comment', 'was', 'added', 'by', 'august', 'utc']'\n",
      "ORIGINAL: '\"Hi Explicit, can you block O Fenian for edit-warring on the Giant's Causeway wp. He has made several edits which can only be described as terrorism.\"'\n",
      "PROCESSED: '['hi', 'explicit', 'can', 'you', 'block', 'o', 'fenian', 'for', 'edit-', 'warring', 'on', 'the', 'giant', \"'s\", 'causeway', 'wp', 'he', 'has', 'made', 'several', 'edits', 'which', 'can', 'only', 'be', 'described', 'as', 'terrorism']'\n",
      "ORIGINAL: '\"Notability of Rurika Kasuga A tag has been placed on Rurika Kasuga, requesting that it be speedily deleted from Wikipedia. This has been done because the article seems to be about a person, group of people, band, club, company, or web content, but it does not indicate how or why the subject is notable, that is, why an article about that subject should be included in Wikipedia. Under the criteria for speedy deletion, articles that do not assert notability may be deleted at any time. Please see the guidelines for what is generally accepted as notable, and if you can indicate why the subject of this article is notable, you may contest the tagging. To do this, add on the top of the page (below the existing db tag) and leave a note on the article's talk page explaining your position. Please do not remove the speedy deletion tag yourself, but don't hesitate to add information to the article that would confirm its subject's notability under the guidelines. For guidelines on specific types of articles, you may want to check out our criteria for biographies, for web sites, for bands, or for companies. Feel free to leave a note on my talk page if you have any questions about this.\"'\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b001c4a01b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcorpus_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             self.train(\n\u001b[1;32m    420\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         total_words, corpus_count = self.scan_vocab(\n\u001b[0;32m--> 481\u001b[0;31m             corpus_iterable=corpus_iterable, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mchecked_string_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9b64d00bfa29>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# Convert to lowercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# Remove duplicated whitespaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mprocessed_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspecial_chars_or_punctuation_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"PROCESSED: '{processed_line}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mprocessed_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    251\u001b[0m         assert any([isinstance(doc, str), isinstance(doc, list),\n\u001b[1;32m    252\u001b[0m                     isinstance(doc, Document)]), 'input should be either str, list or Document'\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk_process\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbulk\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/stanza/pipeline/tokenize_processor.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     88\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_seqlen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenizeProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_SEQ_LENGTH_DEFAULT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                                                \u001b[0morig_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                                                no_ssplit=self.config.get('no_ssplit', False))\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/offensive-language-organization/lib/python3.6/site-packages/stanza/models/tokenization/utils.py\u001b[0m in \u001b[0;36moutput_predictions\u001b[0;34m(output_file, trainer, data_generator, vocab, mwt_dict, max_seqlen, orig_text, no_ssplit, use_regex_tokens)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0meval_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchparas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save('w2v_50dim_model_v2')\n",
    "new_model = gensim.models.Word2Vec.load('w2v_50dim_model_v2')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.similarity('woman', 'man')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model['computer']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.wv.most_similar('computer', topn=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = FastText(sentences, min_count=2, vector_size=50, workers=4)\n",
    "model.save('fastText_50dim_model_v2')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}