{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LteYCMwRP9YV"
   },
   "outputs": [],
   "source": [
    "# IMPORTS \n",
    "import os\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from hate_bert_helper import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z7G6K8p3ORej"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 980 Ti\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS SETUP\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "rn.seed(501)\n",
    "np.random.seed(501)\n",
    "torch.manual_seed(501)\n",
    "torch.cuda.manual_seed(501)\n",
    "\n",
    "\n",
    "MAX_LEN = 128 # max lengrh of a sentence, fed into the network\n",
    "hatebert_model_path = \"./models/hate_bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMv8Io5jIkXb"
   },
   "source": [
    "# Experiments setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_definitions = [\n",
    "    #TOXIC\n",
    "    [(1, \"toxic\", \"other\"),\n",
    "    (1, \"severe_toxic\", \"other\")],\n",
    "    #HATE\n",
    "    [(1, \"identity_hate\", \"other\"),\n",
    "    (2, \"hate_speech\", \"neither\"),\n",
    "    (3, \"hate\", \"none\"),\n",
    "    (7, \"hateful\", \"normal\"),\n",
    "    (10, \"hateful\", \"none\"),\n",
    "    (11, \"hateful\", \"none\"),\n",
    "    (12, \"hate\", \"noHate\"),\n",
    "    (16, \"hateful\", \"non-hateful\"),\n",
    "    (18, \"hateful\", \"normal\"),\n",
    "    (21, \"hatespeech\", \"normal\"),\n",
    "    (25, \"hate\", \"nothate\")],\n",
    "    #ABUSIVE\n",
    "    [(7, \"abusive\", \"normal\"),\n",
    "    (18, \"abusive\", \"normal\")],\n",
    "    #AGGRESSIVE\n",
    "    [(17, \"covertly-aggressive\", \"non-aggressive\"),\n",
    "    (17, \"overtly-aggressive\", \"non-aggressive\")],\n",
    "    #OFFENSIVE\n",
    "    [(2, \"offensive_language\", \"neither\"),\n",
    "    (3, \"offensive\", \"none\"),\n",
    "    (15, \"offensive\", \"non-offensive\"),\n",
    "    (21, \"offensive\", \"normal\")],\n",
    "    #SEXISM\n",
    "    [(4, \"sexism\", \"none\"),\n",
    "    (9, \"sexist\", \"none\"),\n",
    "    (29, \"sexism\", \"none\"),\n",
    "    (30, \"sexism\", \"neither\")],\n",
    "    #CYBERBULLYING\n",
    "    [(6, \"cyberbullying\", \"none\"),\n",
    "    (28, \"cyberbullying\", \"none\")],\n",
    "    #SPAM\n",
    "    [(7, \"spam\", \"normal\"),\n",
    "    (18, \"spam\", \"normal\")],\n",
    "    #RELIGIOUS\n",
    "    [(9, \"religious\", \"none\")],\n",
    "    #HARRASMENT\n",
    "    [(19, \"harrasment\", \"non-harrasment\")],\n",
    "    #OBSCENE\n",
    "    [(1, \"obscene\", \"other\")],\n",
    "    #INSULT\n",
    "    [(1, \"insult\", \"other\")],\n",
    "    #HOMOPHOBIA\n",
    "    [(9, \"homophobic\", \"none\")],\n",
    "    #RACIST\n",
    "    [(9, \"racist\", \"none\")],\n",
    "    #VULGAR\n",
    "    [(27, \"vulgar\", \"non-vulgar\")],\n",
    "    #THREAT\n",
    "    [(1, \"threat\", \"other\")],\n",
    "    #PROFANE\n",
    "    [(3, \"profane\", \"none\")]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Cisco had to deal with a fat cash payout to th...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>@MadamPlumpette I'm decent at editing, no worr...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>@girlziplocked will read. gotta go afk for a b...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>guys. show me the data. show me your github. t...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>@tpw_rules nothings broken. I was just driving...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869279</th>\n",
       "      <td>30</td>\n",
       "      <td>via @weaselzippers: Feminazi Blog Reminds Libe...</td>\n",
       "      <td>sexism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869280</th>\n",
       "      <td>30</td>\n",
       "      <td>I used to have pet bunnies. :) I named them PO...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869281</th>\n",
       "      <td>30</td>\n",
       "      <td>@alex SO GROSS. feeling the urge to shower in ...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869282</th>\n",
       "      <td>30</td>\n",
       "      <td>Purpose of this group is to share the types of...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869283</th>\n",
       "      <td>30</td>\n",
       "      <td>@onebrightlight they made mistakes in the past...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>869284 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        corpus_id                                               text    label\n",
       "0              30  Cisco had to deal with a fat cash payout to th...  neither\n",
       "1              30  @MadamPlumpette I'm decent at editing, no worr...  neither\n",
       "2              30  @girlziplocked will read. gotta go afk for a b...  neither\n",
       "3              30  guys. show me the data. show me your github. t...  neither\n",
       "4              30  @tpw_rules nothings broken. I was just driving...  neither\n",
       "...           ...                                                ...      ...\n",
       "869279         30  via @weaselzippers: Feminazi Blog Reminds Libe...   sexism\n",
       "869280         30  I used to have pet bunnies. :) I named them PO...  neither\n",
       "869281         30  @alex SO GROSS. feeling the urge to shower in ...  neither\n",
       "869282         30  Purpose of this group is to share the types of...  neither\n",
       "869283         30  @onebrightlight they made mistakes in the past...  neither\n",
       "\n",
       "[869284 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS_PATH = \"/home/slavkoz/Projects/ResearchProjects/offensive-language-organization/full_classification_dataset.csv\"\n",
    "datasets = pd.read_csv(DATASETS_PATH)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training corpus 1-toxic ... ... model already exists!\n",
      "Training corpus 1-severe_toxic ... ... model already exists!\n",
      "Training corpus 1-identity_hate ... ... model already exists!\n",
      "Training corpus 2-hate_speech ... ... model already exists!\n",
      "Training corpus 3-hate ... ... model already exists!\n",
      "Training corpus 7-hateful ... ... model already exists!\n",
      "Training corpus 10-hateful ... ... model already exists!\n",
      "Training corpus 11-hateful ... ... model already exists!\n",
      "Training corpus 12-hate ... ... model already exists!\n",
      "Training corpus 16-hateful ... ... model already exists!\n",
      "Training corpus 18-hateful ... ... model already exists!\n",
      "Training corpus 21-hatespeech ... ... model already exists!\n",
      "Training corpus 25-hate ... ... model already exists!\n",
      "Training corpus 7-abusive ... ... model already exists!\n",
      "Training corpus 18-abusive ... ... model already exists!\n",
      "Training corpus 17-covertly-aggressive ... ... model already exists!\n",
      "Training corpus 17-overtly-aggressive ... ... model already exists!\n",
      "Training corpus 2-offensive_language ... ... model already exists!\n",
      "Training corpus 3-offensive ... ... model already exists!\n",
      "Training corpus 15-offensive ... ... model already exists!\n",
      "Training corpus 21-offensive ... ... model already exists!\n",
      "Training corpus 4-sexism ... ... model already exists!\n",
      "Training corpus 9-sexist ... ... model already exists!\n",
      "Training corpus 29-sexism ... ... model already exists!\n",
      "Training corpus 30-sexism ... ... model already exists!\n",
      "Training corpus 6-cyberbullying ... ... model already exists!\n",
      "Training corpus 28-cyberbullying ... ... model already exists!\n",
      "Training corpus 7-spam ... ... model already exists!\n",
      "Training corpus 18-spam ... ... model already exists!\n",
      "Training corpus 9-religious ... ... model already exists!\n",
      "Training corpus 19-harrasment ... ... model already exists!\n",
      "Training corpus 1-obscene ... ... model already exists!\n",
      "Training corpus 1-insult ... ... model already exists!\n",
      "Training corpus 9-homophobic ... ... model already exists!\n",
      "Training corpus 9-racist ... ... model already exists!\n",
      "Training corpus 27-vulgar ... ... model already exists!\n",
      "Training corpus 1-threat ... ... model already exists!\n",
      "Training corpus 3-profane ... ... model already exists!\n"
     ]
    }
   ],
   "source": [
    "for dataset_definition_group in dataset_definitions:\n",
    "    for definition in dataset_definition_group: \n",
    "        corpus_id = definition[0]\n",
    "        pos_label = definition[1]\n",
    "        neg_label = definition[2]\n",
    "        dataset = extract_dataset(datasets, corpus_id, pos_label, neg_label)\n",
    "        print(f\"Training corpus {corpus_id}-{pos_label} ...\", end = \"\")\n",
    "        model_path = \"./models/finetuned_model_\"+str(corpus_id)+\"_\"+str(pos_label)\n",
    "        if os.path.exists(model_path):\n",
    "            print(\" ... model already exists!\")\n",
    "        else:\n",
    "            # Training model\n",
    "            train_and_save(device, \n",
    "                       MAX_LEN, \n",
    "                       hatebert_model_path, \n",
    "                       model_path, \n",
    "                       dataset[\"text\"].values, \n",
    "                       dataset[\"label\"].values, \n",
    "                       pos_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture std_output_single_domain --no-stderr\n",
    "# Check within single domains\n",
    "\n",
    "#for dataset_definitions_list in dataset_definitions[0:8]:\n",
    "#    run_pairwise_analysis(device, MAX_LEN, datasets, dataset_definitions_list)\n",
    "            \n",
    "#with open('std_output_single_domain.txt', 'w') as out:\n",
    "#   out.write(std_output_single_domain.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture std_output_across_domain\n",
    "sys.stdout = open(\"std_output_across_domain.txt\", \"w\")\n",
    "# Check across domains\n",
    "\n",
    "print(\"Evaluation: \\n\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "dataset_definitions_list = [\n",
    "    #TOXIC\n",
    "    (1, \"severe_toxic\", \"other\"),\n",
    "    #HATE\n",
    "    (2, \"hate_speech\", \"neither\"),\n",
    "    #ABUSIVE\n",
    "    (7, \"abusive\", \"normal\"),\n",
    "    #AGGRESSIVE\n",
    "    (17, \"covertly-aggressive\", \"non-aggressive\"),\n",
    "    #OFFENSIVE\n",
    "    (15, \"offensive\", \"non-offensive\"),\n",
    "    #SEXISM\n",
    "    (29, \"sexism\", \"none\"),\n",
    "    #CYBERBULLYING\n",
    "    (6, \"cyberbullying\", \"none\"),\n",
    "    #SPAM\n",
    "    (18, \"spam\", \"normal\"),\n",
    "    #RELIGIOUS\n",
    "    (9, \"religious\", \"none\"),\n",
    "    #HARRASMENT\n",
    "    (19, \"harrasment\", \"non-harrasment\"),\n",
    "    #OBSCENE\n",
    "    (1, \"obscene\", \"other\"),\n",
    "    #INSULT\n",
    "    (1, \"insult\", \"other\"),\n",
    "    #HOMOPHOBIA\n",
    "    (9, \"homophobic\", \"none\"),\n",
    "    #RACIST\n",
    "    (9, \"racist\", \"none\"),\n",
    "    #VULGAR\n",
    "    (27, \"vulgar\", \"non-vulgar\"),\n",
    "    #THREAT\n",
    "    (1, \"threat\", \"other\"),\n",
    "    #PROFANE\n",
    "    (3, \"profane\", \"none\")\n",
    "]\n",
    "\n",
    "run_pairwise_analysis(device, MAX_LEN, datasets, dataset_definitions_list)\n",
    "\n",
    "sys.stdout.close()\n",
    "            \n",
    "#with open('std_output_across_domain.txt', 'w') as out:\n",
    "#   out.write(std_output_across_domain.stdout)\n",
    "#with open('std_output_across_domain.err', 'w') as out:\n",
    "#   out.write(std_output_across_domain.stderr)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "original_HateBERT_finetuned.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:offensive-language-organization]",
   "language": "python",
   "name": "conda-env-offensive-language-organization-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
