{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LteYCMwRP9YV"
   },
   "outputs": [],
   "source": [
    "# IMPORTS \n",
    "import os\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from hate_bert_helper import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z7G6K8p3ORej"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 980 Ti\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS SETUP\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "rn.seed(501)\n",
    "np.random.seed(501)\n",
    "torch.manual_seed(501)\n",
    "torch.cuda.manual_seed(501)\n",
    "\n",
    "\n",
    "MAX_LEN = 128 # max lengrh of a sentence, fed into the network\n",
    "hatebert_model_path = \"./models/hate_bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMv8Io5jIkXb"
   },
   "source": [
    "# Experiments setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_definitions = [\n",
    "    #TOXIC\n",
    "    [(1, \"toxic\", \"other\"),\n",
    "    (1, \"severe_toxic\", \"other\")],\n",
    "    #HATE\n",
    "    [(1, \"identity_hate\", \"other\"),\n",
    "    (2, \"hate_speech\", \"neither\"),\n",
    "    (3, \"hate\", \"none\"),\n",
    "    (7, \"hateful\", \"normal\"),\n",
    "    (10, \"hateful\", \"none\"),\n",
    "    (11, \"hateful\", \"none\"),\n",
    "    (12, \"hate\", \"noHate\"),\n",
    "    (16, \"hateful\", \"non-hateful\"),\n",
    "    (18, \"hateful\", \"normal\"),\n",
    "    (21, \"hatespeech\", \"normal\"),\n",
    "    (25, \"hate\", \"nothate\")],\n",
    "    #ABUSIVE\n",
    "    [(7, \"abusive\", \"normal\"),\n",
    "    (18, \"abusive\", \"normal\")],\n",
    "    #AGGRESSIVE\n",
    "    [(17, \"covertly-aggressive\", \"non-aggressive\"),\n",
    "    (17, \"overtly-aggressive\", \"non-aggressive\")],\n",
    "    #OFFENSIVE\n",
    "    [(2, \"offensive_language\", \"neither\"),\n",
    "    (3, \"offensive\", \"none\"),\n",
    "    (15, \"offensive\", \"non-offensive\"),\n",
    "    (21, \"offensive\", \"normal\")],\n",
    "    #SEXISM\n",
    "    [(4, \"sexism\", \"none\"),\n",
    "    (9, \"sexist\", \"none\"),\n",
    "    (29, \"sexism\", \"none\"),\n",
    "    (30, \"sexism\", \"neither\")],\n",
    "    #CYBERBULLYING\n",
    "    [(6, \"cyberbullying\", \"none\"),\n",
    "    (28, \"cyberbullying\", \"none\")],\n",
    "    #SPAM\n",
    "    [(7, \"spam\", \"normal\"),\n",
    "    (18, \"spam\", \"normal\")],\n",
    "    #HARRASMENT\n",
    "    [(19, \"harrasment\", \"non-harrasment\")],\n",
    "    #OBSCENE\n",
    "    [(1, \"obscene\", \"other\")],\n",
    "    #INSULT\n",
    "    [(1, \"insult\", \"other\")],\n",
    "    #HOMOPHOBIA\n",
    "    [(9, \"homophobic\", \"none\")],\n",
    "    #RACIST\n",
    "    [(9, \"racist\", \"none\")],\n",
    "    #VULGAR\n",
    "    [(27, \"vulgar\", \"non-vulgar\")],\n",
    "    #THREAT\n",
    "    [(1, \"threat\", \"other\")],\n",
    "    #PROFANE\n",
    "    [(3, \"profane\", \"none\")]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Cisco had to deal with a fat cash payout to th...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>@MadamPlumpette I'm decent at editing, no worr...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>@girlziplocked will read. gotta go afk for a b...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>guys. show me the data. show me your github. t...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>@tpw_rules nothings broken. I was just driving...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781481</th>\n",
       "      <td>30</td>\n",
       "      <td>via @weaselzippers: Feminazi Blog Reminds Libe...</td>\n",
       "      <td>sexism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781482</th>\n",
       "      <td>30</td>\n",
       "      <td>I used to have pet bunnies. :) I named them PO...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781483</th>\n",
       "      <td>30</td>\n",
       "      <td>@alex SO GROSS. feeling the urge to shower in ...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781484</th>\n",
       "      <td>30</td>\n",
       "      <td>Purpose of this group is to share the types of...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781485</th>\n",
       "      <td>30</td>\n",
       "      <td>@onebrightlight they made mistakes in the past...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781486 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        corpus_id                                               text    label\n",
       "0              30  Cisco had to deal with a fat cash payout to th...  neither\n",
       "1              30  @MadamPlumpette I'm decent at editing, no worr...  neither\n",
       "2              30  @girlziplocked will read. gotta go afk for a b...  neither\n",
       "3              30  guys. show me the data. show me your github. t...  neither\n",
       "4              30  @tpw_rules nothings broken. I was just driving...  neither\n",
       "...           ...                                                ...      ...\n",
       "781481         30  via @weaselzippers: Feminazi Blog Reminds Libe...   sexism\n",
       "781482         30  I used to have pet bunnies. :) I named them PO...  neither\n",
       "781483         30  @alex SO GROSS. feeling the urge to shower in ...  neither\n",
       "781484         30  Purpose of this group is to share the types of...  neither\n",
       "781485         30  @onebrightlight they made mistakes in the past...  neither\n",
       "\n",
       "[781486 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS_PATH = \"outputs/full_classification_dataset.csv\"\n",
    "datasets = pd.read_csv(DATASETS_PATH)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training corpus 1-toxic ... ... model already exists!\n",
      "Training corpus 1-severe_toxic ... ... model already exists!\n",
      "Training corpus 1-identity_hate ... ... model already exists!\n",
      "Training corpus 2-hate_speech ... ... model already exists!\n",
      "Training corpus 3-hate ... ... model already exists!\n",
      "Training corpus 7-hateful ... ... model already exists!\n",
      "Training corpus 10-hateful ... ... model already exists!\n",
      "Training corpus 11-hateful ... ... model already exists!\n",
      "Training corpus 12-hate ... ... model already exists!\n",
      "Training corpus 16-hateful ... ... model already exists!\n",
      "Training corpus 18-hateful ... ... model already exists!\n",
      "Training corpus 21-hatespeech ... ... model already exists!\n",
      "Training corpus 25-hate ... ... model already exists!\n",
      "Training corpus 7-abusive ... ... model already exists!\n",
      "Training corpus 18-abusive ... ... model already exists!\n",
      "Training corpus 17-covertly-aggressive ... ... model already exists!\n",
      "Training corpus 17-overtly-aggressive ... ... model already exists!\n",
      "Training corpus 2-offensive_language ... ... model already exists!\n",
      "Training corpus 3-offensive ... ... model already exists!\n",
      "Training corpus 15-offensive ... ... model already exists!\n",
      "Training corpus 21-offensive ... ... model already exists!\n",
      "Training corpus 4-sexism ... ... model already exists!\n",
      "Training corpus 9-sexist ...0.0M\n",
      "0.0M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03316373263610117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [24:43<49:27, 1483.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9896232876712329\n",
      "Train loss: 0.02878951472186183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [49:38<24:49, 1489.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9896232876712329\n",
      "Train loss: 0.02647990024432802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [1:14:33<00:00, 1491.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9896232876712329\n",
      "Accuracy: 98.97%\n",
      "F1 micro: 98.97%\n",
      "F1 macro: 49.74%\n",
      "Precission: 0.00%\n",
      "Recall: 0.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     17502\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99     17502\n",
      "   macro avg       0.50      0.49      0.50     17502\n",
      "weighted avg       1.00      0.99      0.99     17502\n",
      "\n",
      "[[17322   180]\n",
      " [    0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training corpus 29-sexism ... ... model already exists!\n",
      "Training corpus 30-sexism ... ... model already exists!\n",
      "Training corpus 6-cyberbullying ... ... model already exists!\n",
      "Training corpus 28-cyberbullying ... ... model already exists!\n",
      "Training corpus 7-spam ... ... model already exists!\n",
      "Training corpus 18-spam ... ... model already exists!\n",
      "Training corpus 19-harrasment ... ... model already exists!\n",
      "Training corpus 1-obscene ... ... model already exists!\n",
      "Training corpus 1-insult ... ... model already exists!\n",
      "Training corpus 9-homophobic ...0.0M\n",
      "0.0M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0307939641860253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [25:04<50:09, 1504.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9864809782608696\n",
      "Train loss: 0.02649940532689865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [50:12<25:06, 1506.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9886209239130435\n",
      "Train loss: 0.02454336822475902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [1:15:23<00:00, 1507.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9880095108695651\n",
      "Accuracy: 98.78%\n",
      "F1 micro: 98.78%\n",
      "F1 macro: 78.26%\n",
      "Precission: 50.53%\n",
      "Recall: 65.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     17427\n",
      "           1       0.51      0.66      0.57       219\n",
      "\n",
      "    accuracy                           0.99     17646\n",
      "   macro avg       0.75      0.82      0.78     17646\n",
      "weighted avg       0.99      0.99      0.99     17646\n",
      "\n",
      "[[17286   141]\n",
      " [   75   144]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training corpus 9-racist ...0.0M\n",
      "0.0M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09857102306129413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [25:25<50:51, 1525.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9761677665498041\n",
      "Train loss: 0.09082476336241113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [50:54<25:27, 1527.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9750850690864096\n",
      "Train loss: 0.08304651832154601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [1:16:26<00:00, 1528.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9742859352443803\n",
      "Accuracy: 97.52%\n",
      "F1 micro: 97.52%\n",
      "F1 macro: 72.78%\n",
      "Precission: 40.88%\n",
      "Recall: 54.78%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     17539\n",
      "           1       0.41      0.55      0.47       356\n",
      "\n",
      "    accuracy                           0.98     17895\n",
      "   macro avg       0.70      0.77      0.73     17895\n",
      "weighted avg       0.98      0.98      0.98     17895\n",
      "\n",
      "[[17257   282]\n",
      " [  161   195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training corpus 27-vulgar ... ... model already exists!\n",
      "Training corpus 1-threat ... ... model already exists!\n",
      "Training corpus 3-profane ... ... model already exists!\n"
     ]
    }
   ],
   "source": [
    "for dataset_definition_group in dataset_definitions:\n",
    "    for definition in dataset_definition_group: \n",
    "        corpus_id = definition[0]\n",
    "        pos_label = definition[1]\n",
    "        neg_label = definition[2]\n",
    "        dataset = extract_dataset(datasets, corpus_id, pos_label, neg_label)\n",
    "        print(f\"Training corpus {corpus_id}-{pos_label} ...\", end = \"\")\n",
    "        model_path = \"./models/finetuned_model_\"+str(corpus_id)+\"_\"+str(pos_label)\n",
    "        if os.path.exists(model_path):\n",
    "            print(\" ... model already exists!\")\n",
    "        else:\n",
    "            # Training model\n",
    "            train_and_save(device, \n",
    "                       MAX_LEN, \n",
    "                       hatebert_model_path, \n",
    "                       model_path, \n",
    "                       dataset[\"text\"].values, \n",
    "                       dataset[\"label\"].values, \n",
    "                       pos_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open(\"outputs/std_output_single_domain.txt\", \"w\")\n",
    "# Check within single domains\n",
    "\n",
    "for dataset_definitions_list in dataset_definitions[0:8]:\n",
    "    run_pairwise_analysis(device, \n",
    "                          MAX_LEN, \n",
    "                          datasets, \n",
    "                          dataset_definitions_list,\n",
    "                          dataset_definitions_list)\n",
    "            \n",
    "sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open(\"outputs/std_output_across_domain.txt\", \"w\")\n",
    "# Check across domains\n",
    "\n",
    "print(\"Evaluation: \\n\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "dataset_definitions_list_trained = [\n",
    "    #TOXIC\n",
    "    (1, \"severe_toxic\", \"other\"),\n",
    "    #HATE\n",
    "    (2, \"hate_speech\", \"neither\"),\n",
    "    #ABUSIVE\n",
    "    (7, \"abusive\", \"normal\"),\n",
    "    #AGGRESSIVE\n",
    "    (17, \"covertly-aggressive\", \"non-aggressive\"),\n",
    "    #OFFENSIVE\n",
    "    (15, \"offensive\", \"non-offensive\"),\n",
    "    #SEXISM\n",
    "    (29, \"sexism\", \"none\"),\n",
    "    #CYBERBULLYING\n",
    "    (6, \"cyberbullying\", \"none\"),\n",
    "    #SPAM\n",
    "    (18, \"spam\", \"normal\"),\n",
    "    #HARRASMENT\n",
    "    (19, \"harrasment\", \"non-harrasment\"),\n",
    "    #OBSCENE\n",
    "    (1, \"obscene\", \"other\"),\n",
    "    #INSULT\n",
    "    (1, \"insult\", \"other\"),\n",
    "    #HOMOPHOBIA\n",
    "    (9, \"homophobic\", \"none\"),\n",
    "    #RACIST\n",
    "    (9, \"racist\", \"none\"),\n",
    "    #VULGAR\n",
    "    (27, \"vulgar\", \"non-vulgar\"),\n",
    "    #THREAT\n",
    "    (1, \"threat\", \"other\"),\n",
    "    #PROFANE\n",
    "    (3, \"profane\", \"none\")\n",
    "]\n",
    "\n",
    "dataset_definitions_list_to_test = [\n",
    "    #TOXIC\n",
    "    (1, \"severe_toxic\", \"other\"),\n",
    "    #HATE\n",
    "    (2, \"hate_speech\", \"neither\"),\n",
    "    #ABUSIVE\n",
    "    (7, \"abusive\", \"normal\"),\n",
    "    #AGGRESSIVE\n",
    "    (17, \"covertly-aggressive\", \"non-aggressive\"),\n",
    "    #OFFENSIVE\n",
    "    (15, \"offensive\", \"non-offensive\"),\n",
    "    #SEXISM\n",
    "    (29, \"sexism\", \"none\"),\n",
    "    #CYBERBULLYING\n",
    "    (6, \"cyberbullying\", \"none\"),\n",
    "    #SPAM\n",
    "    (18, \"spam\", \"normal\"),\n",
    "    #HARRASMENT\n",
    "    (19, \"harrasment\", \"non-harrasment\"),\n",
    "    #OBSCENE\n",
    "    (1, \"obscene\", \"other\"),\n",
    "    #INSULT\n",
    "    (1, \"insult\", \"other\"),\n",
    "    #HOMOPHOBIA\n",
    "    (9, \"homophobic\", \"none\"),\n",
    "    #RACIST\n",
    "    (9, \"racist\", \"none\"),\n",
    "    #VULGAR\n",
    "    (27, \"vulgar\", \"non-vulgar\"),\n",
    "    #THREAT\n",
    "    (1, \"threat\", \"other\"),\n",
    "    #PROFANE\n",
    "    (3, \"profane\", \"none\")\n",
    "]\n",
    "\n",
    "run_pairwise_analysis(device, \n",
    "                      MAX_LEN, \n",
    "                      datasets, \n",
    "                      dataset_definitions_list_trained,\n",
    "                      dataset_definitions_list_to_test\n",
    "                     )\n",
    "\n",
    "sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "original_HateBERT_finetuned.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:offensive-language-organization]",
   "language": "python",
   "name": "conda-env-offensive-language-organization-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
